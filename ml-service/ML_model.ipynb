{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Io9Ri5GQiZaE",
        "outputId": "e4c5fcdc-a2b6-4412-9af4-a28bfd0cb15c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“ Creating app.py file...\n",
            "ğŸš€ Installing Libraries & Cloudflare Tunnel...\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hâš¡ Starting Streamlit App (This takes ~60 seconds to load models)...\n",
            "--------------------------------------------------\n",
            "ğŸ‘‡ CLICK THIS LINK TO OPEN YOUR APP ğŸ‘‡\n",
            "https://menus-fusion-enemies-ranges.trycloudflare.com\n",
            "--------------------------------------------------\n",
            "â³ Waiting for app to load models... (Watch the logs below)\n",
            "PLEASE WAIT until you see 'Model loaded' before clicking the link!\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\n",
            "\n",
            "  You can now view your Streamlit app in your browser.\n",
            "\n",
            "  Local URL: http://localhost:8501\n",
            "  Network URL: http://172.28.0.12:8501\n",
            "  External URL: http://35.196.49.218:8501\n",
            "\n",
            "2025-12-18 17:39:06.340682: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-12-18 17:39:06.345912: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-12-18 17:39:06.358850: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1766079546.383669     673 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1766079546.391222     673 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1766079546.412869     673 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766079546.412919     673 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766079546.412923     673 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766079546.412927     673 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-18 17:39:06.418891: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
            "Generating train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 853/853 [00:00<00:00, 10758.83 examples/s]\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# SUPER CELL: CREATE APP + RUN TUNNEL\n",
        "# ==========================================\n",
        "import urllib\n",
        "import time\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "# --- STEP 1: WRITE THE APP CODE TO A FILE ---\n",
        "print(\"ğŸ“ Creating app.py file...\")\n",
        "\n",
        "code = \"\"\"\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import pdfplumber\n",
        "import re\n",
        "import os\n",
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# 1. CONFIGURATION & STYLING\n",
        "st.set_page_config(page_title=\"AI Resume Matcher\", layout=\"wide\")\n",
        "\n",
        "st.markdown(\\\"\\\"\\\"\n",
        "<style>\n",
        "    .stApp { background-color: #0E1117; }\n",
        "    div.css-1r6slb0.e1tzin5v2 { background-color: #161B22; border: 1px solid #30363D; border-radius: 10px; padding: 20px; margin-bottom: 20px; }\n",
        "    .match-circle { font-size: 24px; font-weight: bold; color: white; background-color: #21262D; border-radius: 50%; width: 60px; height: 60px; display: flex; align-items: center; justify-content: center; border: 3px solid; }\n",
        "    .skill-badge-missing { background-color: rgba(255, 0, 0, 0.1); color: #FF6E6E; border: 1px solid #FF6E6E; padding: 4px 8px; border-radius: 15px; font-size: 0.85em; margin-right: 5px; margin-bottom: 5px; display: inline-block; }\n",
        "    .match-badge-high { background-color: rgba(0, 255, 0, 0.1); color: #2EA043; border: 1px solid #2EA043; padding: 4px 8px; border-radius: 4px; }\n",
        "    .match-badge-med { background-color: rgba(255, 165, 0, 0.1); color: #D29922; border: 1px solid #D29922; padding: 4px 8px; border-radius: 4px; }\n",
        "    .match-badge-low { background-color: rgba(255, 0, 0, 0.1); color: #F85149; border: 1px solid #F85149; padding: 4px 8px; border-radius: 4px; }\n",
        "</style>\n",
        "\\\"\\\"\\\", unsafe_allow_html=True)\n",
        "\n",
        "# 2. BACKEND LOGIC\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    return SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "@st.cache_data\n",
        "def load_jobs_data():\n",
        "    dataset = load_dataset(\"jacob-hugging-face/job-descriptions\", split=\"train[:300]\")\n",
        "    df = pd.DataFrame(dataset)\n",
        "    if 'job_description' in df.columns:\n",
        "        df = df.rename(columns={'job_description': 'Job Description', 'position_title': 'Job Title'})\n",
        "    return df\n",
        "\n",
        "model = load_model()\n",
        "df_jobs = load_jobs_data()\n",
        "\n",
        "def get_skill_taxonomies():\n",
        "    tech_skills = {\n",
        "        \"python\", \"java\", \"c++\", \"c#\", \"javascript\", \"typescript\", \"ruby\", \"php\", \"swift\", \"kotlin\",\n",
        "        \"react\", \"angular\", \"vue\", \"node.js\", \"django\", \"flask\", \"spring boot\", \"dotnet\",\n",
        "        \"html\", \"css\", \"sql\", \"nosql\", \"mysql\", \"postgresql\", \"mongodb\", \"oracle\",\n",
        "        \"aws\", \"azure\", \"gcp\", \"docker\", \"kubernetes\", \"jenkins\", \"terraform\", \"git\", \"github\",\n",
        "        \"gitlab\", \"jira\", \"confluence\", \"tableau\", \"powerbi\", \"excel\", \"figma\",\n",
        "        \"machine learning\", \"deep learning\", \"nlp\", \"tensorflow\", \"pytorch\", \"scikit-learn\",\n",
        "        \"oop\", \"object oriented\", \"functional programming\", \"rest api\", \"graphql\", \"ci/cd\",\n",
        "        \"devops\", \"agile\", \"scrum\", \"kanban\", \"sdlc\", \"data structures\", \"algorithms\",\n",
        "        \"linux\", \"unix\", \"bash\", \"shell\"\n",
        "    }\n",
        "    soft_skills = {\n",
        "        \"communication\", \"leadership\", \"teamwork\", \"problem solving\", \"critical thinking\",\n",
        "        \"time management\", \"adaptability\", \"collaboration\", \"creativity\", \"emotional intelligence\",\n",
        "        \"negotiation\", \"conflict resolution\", \"decision making\", \"mentoring\", \"presentation\",\n",
        "        \"active listening\", \"flexibility\", \"work ethic\", \"detail oriented\", \"stakeholder management\"\n",
        "    }\n",
        "    return tech_skills, soft_skills\n",
        "\n",
        "TECH_SKILLS, SOFT_SKILLS = get_skill_taxonomies()\n",
        "ALL_SKILLS = TECH_SKILLS.union(SOFT_SKILLS)\n",
        "\n",
        "def get_implications():\n",
        "    return {\n",
        "        \"oop\": [\"java\", \"c++\", \"c#\", \"python\", \"ruby\"],\n",
        "        \"object oriented\": [\"java\", \"c++\", \"c#\", \"python\", \"ruby\"],\n",
        "        \"cloud\": [\"aws\", \"azure\", \"gcp\"],\n",
        "        \"frontend\": [\"react\", \"angular\", \"vue\", \"html\", \"css\", \"javascript\"],\n",
        "        \"backend\": [\"node.js\", \"django\", \"spring\", \"flask\"],\n",
        "        \"database\": [\"sql\", \"mysql\", \"postgresql\", \"mongodb\", \"oracle\"],\n",
        "        \"ci/cd\": [\"jenkins\", \"gitlab\", \"github actions\"],\n",
        "        \"devops\": [\"docker\", \"kubernetes\", \"jenkins\", \"terraform\"]\n",
        "    }\n",
        "IMPLICATION_RULES = get_implications()\n",
        "\n",
        "def extract_text_from_pdf(uploaded_file):\n",
        "    text = \"\"\n",
        "    try:\n",
        "        with pdfplumber.open(uploaded_file) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                text += page.extract_text() + \" \"\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error reading PDF: {e}\")\n",
        "        return None\n",
        "    return text.strip()\n",
        "\n",
        "def analyze_split_gaps(resume_text, jd_text):\n",
        "    resume_lower = resume_text.lower()\n",
        "    jd_lower = jd_text.lower()\n",
        "    missing_tech = []\n",
        "    missing_soft = []\n",
        "\n",
        "    def check_category(category_set, output_list):\n",
        "        required = set()\n",
        "        for skill in category_set:\n",
        "            pattern = r'\\\\b' + re.escape(skill) + r'\\\\b'\n",
        "            if re.search(pattern, jd_lower):\n",
        "                required.add(skill)\n",
        "\n",
        "        for skill in required:\n",
        "            pattern = r'\\\\b' + re.escape(skill) + r'\\\\b'\n",
        "            if not re.search(pattern, resume_lower):\n",
        "                found_implied = False\n",
        "                if skill in IMPLICATION_RULES:\n",
        "                    for evidence in IMPLICATION_RULES[skill]:\n",
        "                        evidence_pattern = r'\\\\b' + re.escape(evidence) + r'\\\\b'\n",
        "                        if re.search(evidence_pattern, resume_lower):\n",
        "                            found_implied = True\n",
        "                            break\n",
        "                if not found_implied:\n",
        "                    output_list.append(skill.title())\n",
        "\n",
        "    check_category(TECH_SKILLS, missing_tech)\n",
        "    check_category(SOFT_SKILLS, missing_soft)\n",
        "    return missing_tech, missing_soft\n",
        "\n",
        "def calculate_keyword_score(resume_text, jd_text):\n",
        "    jd_lower = jd_text.lower()\n",
        "    resume_lower = resume_text.lower()\n",
        "    required_skills = set()\n",
        "    for skill in ALL_SKILLS:\n",
        "        pattern = r'\\\\b' + re.escape(skill) + r'\\\\b'\n",
        "        if re.search(pattern, jd_lower):\n",
        "            required_skills.add(skill)\n",
        "\n",
        "    if not required_skills: return 0.0\n",
        "\n",
        "    matched_skills = 0\n",
        "    for skill in required_skills:\n",
        "        pattern = r'\\\\b' + re.escape(skill) + r'\\\\b'\n",
        "        if re.search(pattern, resume_lower):\n",
        "            matched_skills += 1\n",
        "        elif skill in IMPLICATION_RULES:\n",
        "            for evidence in IMPLICATION_RULES[skill]:\n",
        "                evidence_pattern = r'\\\\b' + re.escape(evidence) + r'\\\\b'\n",
        "                if re.search(evidence_pattern, resume_lower):\n",
        "                    matched_skills += 1\n",
        "                    break\n",
        "    return (matched_skills / len(required_skills)) * 100\n",
        "\n",
        "def match_resume_to_jobs_hybrid(resume_text, df):\n",
        "    resume_embedding = model.encode(resume_text, convert_to_tensor=True)\n",
        "    jd_embeddings = model.encode(df['Job Description'].tolist(), convert_to_tensor=True)\n",
        "    cosine_scores = util.cos_sim(resume_embedding, jd_embeddings)[0]\n",
        "\n",
        "    final_scores = []\n",
        "    for i, jd_text in enumerate(df['Job Description']):\n",
        "        semantic_score = float(cosine_scores[i]) * 100\n",
        "        keyword_score = calculate_keyword_score(resume_text, jd_text)\n",
        "        final_score = (semantic_score * 0.70) + (keyword_score * 0.30)\n",
        "        final_scores.append(round(final_score, 1))\n",
        "\n",
        "    df['Match Percentage'] = final_scores\n",
        "    return df.sort_values(by='Match Percentage', ascending=False)\n",
        "\n",
        "# 3. FRONTEND UI\n",
        "col_header1, col_header2 = st.columns([3, 1])\n",
        "with col_header1:\n",
        "    st.title(\"Your Career Matches\")\n",
        "    st.markdown(\"Based on your resume analysis against **300 real-world job descriptions**.\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload your Resume (PDF)\", type=[\"pdf\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    with st.spinner(\"Analyzing Resume and Matching Jobs...\"):\n",
        "        resume_text = extract_text_from_pdf(uploaded_file)\n",
        "\n",
        "        if resume_text:\n",
        "            results = match_resume_to_jobs_hybrid(resume_text, df_jobs)\n",
        "            top_matches = results.head(6)\n",
        "\n",
        "            st.markdown(\"---\")\n",
        "            for row_idx in range(2):\n",
        "                cols = st.columns(3)\n",
        "                for col_idx in range(3):\n",
        "                    data_idx = row_idx * 3 + col_idx\n",
        "                    if data_idx >= len(top_matches): break\n",
        "\n",
        "                    row_data = top_matches.iloc[data_idx]\n",
        "                    score = row_data['Match Percentage']\n",
        "                    job_title = row_data['Job Title']\n",
        "                    jd_text = row_data['Job Description']\n",
        "\n",
        "                    tech_gaps, soft_gaps = analyze_split_gaps(resume_text, jd_text)\n",
        "                    total_gaps = len(tech_gaps) + len(soft_gaps)\n",
        "\n",
        "                    if score >= 75:\n",
        "                        badge_class = \"match-badge-high\"\n",
        "                        border_color = \"#2EA043\"\n",
        "                        summary = \"Your technical skills align very well with this role.\"\n",
        "                    elif score >= 60:\n",
        "                        badge_class = \"match-badge-med\"\n",
        "                        border_color = \"#D29922\"\n",
        "                        summary = \"Good match. A few key skills would make you a top candidate.\"\n",
        "                    else:\n",
        "                        badge_class = \"match-badge-low\"\n",
        "                        border_color = \"#F85149\"\n",
        "                        summary = \"Significant skill gaps found for this specific role requirement.\"\n",
        "\n",
        "                    with cols[col_idx]:\n",
        "                        with st.container():\n",
        "                            c1, c2 = st.columns([3, 1])\n",
        "                            with c1: st.subheader(f\"ğŸ“Œ {job_title}\")\n",
        "                            with c2: st.markdown(f'<div class=\"match-circle\" style=\"border-color: {border_color};\">{int(score)}</div>', unsafe_allow_html=True)\n",
        "\n",
        "                            st.markdown(f'<span class=\"{badge_class}\">{score}% Match</span>', unsafe_allow_html=True)\n",
        "                            st.markdown(f\"<p style='color: #8B949E; font-size: 0.9em; margin-top: 10px;'>{summary}</p>\", unsafe_allow_html=True)\n",
        "\n",
        "                            st.markdown(f\"##### âš ï¸ Skills to Learn ({total_gaps})\")\n",
        "                            badge_html = \"\"\n",
        "                            for skill in tech_gaps[:3]:\n",
        "                                badge_html += f'<span class=\"skill-badge-missing\">{skill}</span>'\n",
        "\n",
        "                            if not tech_gaps and not soft_gaps:\n",
        "                                st.markdown(\"<small style='color: green;'>Perfect technical match!</small>\", unsafe_allow_html=True)\n",
        "                            else:\n",
        "                                st.markdown(badge_html, unsafe_allow_html=True)\n",
        "\n",
        "                            with st.expander(\"View All Skills & Gaps\"):\n",
        "                                st.write(\"**Job Description Snippet:**\")\n",
        "                                st.caption(jd_text[:200] + \"...\")\n",
        "                                st.write(\"**Missing Technical Skills:**\")\n",
        "                                st.write(\", \".join(tech_gaps) if tech_gaps else \"None\")\n",
        "                                st.write(\"**Missing Soft Skills:**\")\n",
        "                                st.write(\", \".join(soft_gaps) if soft_gaps else \"None\")\n",
        "                        st.markdown(\"---\")\n",
        "else:\n",
        "    st.info(\"ğŸ‘† Please upload your resume PDF to see your career matches.\")\n",
        "\"\"\"\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(code)\n",
        "\n",
        "# --- STEP 2: INSTALL DEPENDENCIES & TUNNEL ---\n",
        "print(\"ğŸš€ Installing Libraries & Cloudflare Tunnel...\")\n",
        "!pip install streamlit sentence-transformers pandas pdfplumber datasets scikit-learn -q\n",
        "!wget -q -nc https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "!chmod +x cloudflared-linux-amd64\n",
        "\n",
        "# --- STEP 3: RUN THE APP ---\n",
        "print(\"âš¡ Starting Streamlit App (This takes ~60 seconds to load models)...\")\n",
        "!pkill -f streamlit\n",
        "!pkill -f cloudflared\n",
        "\n",
        "# Run Streamlit in background and log to a file\n",
        "with open(\"streamlit_logs.txt\", \"w\") as log_file:\n",
        "    process = subprocess.Popen([\"streamlit\", \"run\", \"app.py\"], stdout=log_file, stderr=log_file)\n",
        "\n",
        "# Run Tunnel\n",
        "!nohup ./cloudflared-linux-amd64 tunnel --url http://localhost:8501 > tunnel_logs.txt 2>&1 &\n",
        "\n",
        "time.sleep(5)\n",
        "print(\"--------------------------------------------------\")\n",
        "print(\"ğŸ‘‡ CLICK THIS LINK TO OPEN YOUR APP ğŸ‘‡\")\n",
        "!grep -o 'https://.*\\.trycloudflare.com' tunnel_logs.txt | head -n 1\n",
        "print(\"--------------------------------------------------\")\n",
        "\n",
        "print(\"â³ Waiting for app to load models... (Watch the logs below)\")\n",
        "print(\"PLEASE WAIT until you see 'Model loaded' before clicking the link!\")\n",
        "!tail -f streamlit_logs.txt"
      ]
    }
  ]
}